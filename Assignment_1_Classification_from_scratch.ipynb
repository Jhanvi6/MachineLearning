{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1/Classification from scratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka0TtNAkQmNV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c9fc7259-e6fa-41cc-fdf5-35946a9ca90c"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import os\n",
        "print(os.listdir(\"./Input/train\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['labels_training.h5', 'images_training.h5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYbT0TmlQqdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c39c0c98-7d2e-4a57-c359-c0db4288181f"
      },
      "source": [
        "with h5py.File('./Input/train/images_training.h5','r') as H:\n",
        "    data_train = np.copy(H['datatrain'])\n",
        "with h5py.File('./Input/train/labels_training.h5','r') as H:\n",
        "    label_train = np.copy(H['labeltrain'])\n",
        "with h5py.File('./Input/test/images_testing.h5','r') as H:\n",
        "    data_test = np.copy(H['datatest'])\n",
        "with h5py.File('./Input/test/labels_testing_2000.h5','r') as H:\n",
        "    label_test = np.copy(H['labeltest'])\n",
        "\n",
        "\n",
        "# using H['datatest'], H['labeltest'] for test dataset.\n",
        "print(data_train.shape,label_train.shape)\n",
        "print(data_test.shape,label_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000, 784) (30000,)\n",
            "(5000, 784) (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtDyMwhqI1_h"
      },
      "source": [
        "PCA MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZluUr_oopjr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "16e4899c-a90a-4944-a968-839413e1fca6"
      },
      "source": [
        "%%time\n",
        "#STANDARDIZE THE TRAINING DATA\n",
        "data_trainx = (data_train - np.mean(data_train,axis=0))/ np.std(data_train)\n",
        "#STANDARDIZE THE TESTING DATA\n",
        "data_testx = (data_test - np.mean(data_train,axis=0))/ np.std(data_train)\n",
        "#DIMENSION REDUCTION OF TRAINING DATA USING SINGLE VALUE DECOMPOSITION\n",
        "U, s, Vt = np.linalg.svd(data_trainx, full_matrices=False)\n",
        "S = np.diag(s)\n",
        "#CUMULATIVE VARIANCE EXPLAINED BY THE FEATURES\n",
        "var_explained = np.cumsum(s**2/np.sum(s**2))\n",
        "#NUMBER OF COMPONENTS THAT EXPLAIN 95% OF THE DATA\n",
        "n_components = np.argmax(var_explained > 0.95)\n",
        "#REDEFINE Vt\n",
        "Vt = Vt[:n_components,:]\n",
        "#TRAINING DATA TRANSFORMATION\n",
        "data_train_transform = data_trainx.dot(Vt.T)\n",
        "print(\"The dimensions of transformed data_train are: \",data_train_transform.shape)\n",
        "#TESTING DATA TRANSFORMATION\n",
        "data_test_transform = data_testx.dot(Vt.T)\n",
        "print(\"The dimensions of transformed data_test are: \",data_test_transform.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dimensions of transformed data_train are:  (30000, 187)\n",
            "The dimensions of transformed data_test are:  (5000, 187)\n",
            "CPU times: user 11.9 s, sys: 1.19 s, total: 13.1 s\n",
            "Wall time: 7.07 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXq4oH0tg9Wc"
      },
      "source": [
        "DIVIDE TRANSFORMED DATA INTO TRAINING AND VALIDATION DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT-ts4Vpg7bJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "9424d2c0-4201-47c0-9107-2d1298a49ccb"
      },
      "source": [
        "%%time\n",
        "#DIVIDE TRAINING DATA IN TRAIN AND VALIDATE PARTITIONS\n",
        "n_comp = int(0.8*len(data_train_transform))                  #divide data into 80:20 ratio for training and validation\n",
        "train_data, validate_data = data_train_transform[:n_comp], data_train_transform[n_comp:]\n",
        "train_label,validate_label = label_train[:n_comp], label_train[n_comp:]\n",
        "#SUBSET THE FIRST 2000 RWS OF TEST DATA TO CHECK OUR PERFORMANCE ON TEST DATA\n",
        "data_try = data_test_transform[:2000,:]\n",
        "\n",
        "print('The size of training data is : ',train_data.shape)\n",
        "print('The size of validation data is : ',validate_data.shape)\n",
        "print('The size of training labels is : ',train_label.shape)\n",
        "print('The size of validation labels is :',validate_label.shape)\n",
        "print('The size of test data subset is :',data_try.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of training data is :  (24000, 187)\n",
            "The size of validation data is :  (6000, 187)\n",
            "The size of training labels is :  (24000,)\n",
            "The size of validation labels is : (6000,)\n",
            "The size of test data subset is : (2000, 187)\n",
            "CPU times: user 2.33 ms, sys: 0 ns, total: 2.33 ms\n",
            "Wall time: 7.95 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "610Mi5m7DiYE"
      },
      "source": [
        "KNN CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr2iPdY3DlOU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "97cbd88f-1cb4-4c55-fa29-202cd3922f9d"
      },
      "source": [
        "%%time\n",
        "class KNN():\n",
        "    def __init__(self, k):\n",
        "        self.k = k\n",
        "    #TRAIN THE CLASSIFIER\n",
        "    def train(self,data_train,data_label):\n",
        "        self.y = data_label \n",
        "        self.X = data_train        \n",
        "   \n",
        "    #COMPUTE THE DISTANCE BETWEEN THE LABELS\n",
        "    def  compute_distance(self, X_test):\n",
        "        num_train = self.X.shape[0]\n",
        "        num_test = X_test.shape[0]  \n",
        "        distances = np.zeros((num_test,num_train))\n",
        "\n",
        "        for i in range(num_test):\n",
        "            distances[i,:] = np.sqrt(np.sum((self.X - X_test[i,:])**2, axis =1))\n",
        "        return distances\n",
        "\n",
        "    #PREDICT THE LABELS BASED ON THE DISTANCE \n",
        "    def predict(self, X_test):\n",
        "        distances = self.compute_distance(X_test)\n",
        "        return self.predict_labels(distances)\n",
        "    \n",
        "    #PREDICT THE LABEL FOR A ROW BASED ON THE K NEAREST NEIGHBORS\n",
        "    def predict_labels(self,distances):\n",
        "        num_test = distances.shape[0]     #shape of test data\n",
        "        y_pred = np.zeros(num_test)\n",
        "                    \n",
        "        for i in range(num_test):\n",
        "          y_indices = np.argsort(distances[i,:]) \n",
        "          k_closest_classes = self.y[y_indices[:self.k]]             \n",
        "          y_pred[i] = np.argmax(np.bincount(k_closest_classes))\n",
        "          \n",
        "        return y_pred\n",
        "\n",
        "#RUN THE KNN CLASSIFIER\n",
        "if __name__ == \"__main__\" :\n",
        "    data_train = train_data\n",
        "    data_label = train_label\n",
        "    #SET K NEAREST NEIGHBOR VALUE\n",
        "    k_nearest_neighbors = KNN(k = 6)\n",
        "    #TRAIN THE KNN CLASSIFIER\n",
        "    k_nearest_neighbors.train(data_train,data_label)\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 960 µs, sys: 121 µs, total: 1.08 ms\n",
            "Wall time: 547 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "474mr1dkva8x"
      },
      "source": [
        "\n",
        "VALIDATE THE KNN CLASSIFIER USING THE VALIDATE DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwvLuhCQvats",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "a06768b1-bc00-4e83-8cb5-f07b0f0f06a8"
      },
      "source": [
        "%%time\n",
        "#VALIDATE THE KNN CLASSIFIER ON VALIDATE_DATA DATASET\n",
        "prediction = k_nearest_neighbors.predict(validate_data)\n",
        "print(\"The accuracy for k = 6 is \", sum(prediction == validate_label)/validate_label.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy for k = 6 is  0.86\n",
            "CPU times: user 57.6 s, sys: 590 ms, total: 58.2 s\n",
            "Wall time: 58.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYQCyieyyfk0"
      },
      "source": [
        "TEST THE KNN CLASSIFIER ON 2000 ROWS OF TEST DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzPRmYRFyOz1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "96c06b44-b818-4da2-f7c1-1ddfcb165832"
      },
      "source": [
        "%%time\n",
        "#TEST THE KNN CLASSIFIER ON FIRST 2000 VALUES OF TEST DATASET\n",
        "y_pred = k_nearest_neighbors.predict(data_try)\n",
        "print(\"The accuracy for k = 6 is\" , sum(y_pred == label_test)/label_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy for k = 6 is 0.843\n",
            "CPU times: user 18.8 s, sys: 101 ms, total: 18.9 s\n",
            "Wall time: 18.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZOe_ryVvIMo"
      },
      "source": [
        "PREDICT THE LABELS OF TRANSFORMED TEST DATA USING THE KNN CLASSIFIER "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrRAC8hiKl67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "95700c5c-30d3-4780-bd40-6f01b249a678"
      },
      "source": [
        "%%time\n",
        "#PREDICT LABELS USING KNN CLASSIFIER\n",
        "predictions_knn = k_nearest_neighbors.predict(data_test_transform)\n",
        "print(\"The shape of the knn predictions dataset is\", predictions_knn.shape)\n",
        "#print(\"The accuracy of knn classifier on the test data is\" , sum(predictions_knn== labels_of_full_dataset)/labels_of_full_dataset.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the knn predictions dataset is (5000,)\n",
            "CPU times: user 46.1 s, sys: 209 ms, total: 46.3 s\n",
            "Wall time: 46.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_Z3DnNyR5La"
      },
      "source": [
        "NAIVE BAYES CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO5_49YN3b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ae36359b-af52-4c94-f6ca-d6cbdf1c333a"
      },
      "source": [
        "%%time\n",
        "class NaiveBayes:\n",
        "    #FIT THE DATA INTO THE ALGORITHM\n",
        "    def train(self,X,y):\n",
        "        self._class = np.unique(y)\n",
        "        n_samp, n_feat = X.shape       \n",
        "        n_class = len(self._class)\n",
        "        #INITIALISE MEAN, VARIANCE AND PRIOR PROBABILITIES\n",
        "        self._priors = np.zeros(n_class, dtype = np.float64) \n",
        "        self._var = np.zeros((n_class, n_feat), dtype = np.float64)\n",
        "        self._mean = np.zeros((n_class, n_feat), dtype = np.float64)\n",
        "\n",
        "        for cl in self._class:\n",
        "            X_cl =X[cl==y]\n",
        "            self._var[cl,:] = X_cl.var(axis=0)           \n",
        "            self._priors[cl] = X_cl.shape[0]/float(n_samp)\n",
        "            self._mean[cl,:] = X_cl.mean(axis=0)\n",
        "            \n",
        "\n",
        "    #HELP FUNCTION TO CALCULATE THE PROBABILITY DENSITY\n",
        "    def _pdf(self, x, class_id):\n",
        "        variance = self._var[class_id]\n",
        "        mean = self._mean[class_id]        \n",
        "        prob_den = (np.exp(- (x-mean)**2/(2*variance)))/(np.sqrt(2*np.pi*variance))\n",
        "        return prob_den\n",
        "\n",
        "    #HELP FUNCTION TO PREDICT FUNCTION THE MOST PROBABLE LABEL\n",
        "    def _predict(self,x):\n",
        "        posterior = []\n",
        "        for id, cl in enumerate(self._class):           \n",
        "            class_cond = np.sum(np.log(self._pdf(x,id)))\n",
        "            prior = np.log(self._priors[id])\n",
        "            post = prior + class_cond\n",
        "            posterior.append(post)\n",
        "\n",
        "        return self._class[np.argmax(posterior)]\n",
        "\n",
        "    #PREDICT THE LABELS OF THE DATA\n",
        "    def predict(self,X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return y_pred\n",
        "    \n",
        "#RUN THE NAIVE BAYES CLASSIFIER\n",
        "if __name__ == \"__main__\" :\n",
        "    data_train = train_data\n",
        "    data_label = train_label\n",
        "    ba = NaiveBayes()\n",
        "    #TRAIN THE CLASSIFIER\n",
        "    ba.train(data_train, data_label)\n",
        "    \n",
        "   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19.5 ms, sys: 0 ns, total: 19.5 ms\n",
            "Wall time: 24.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3tVnUfsuvxW"
      },
      "source": [
        "VALIDATE THE NAIVE BAYES CLASSIFIER USING VALIDATE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAQ9wW7muqkX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "d4a318ca-b865-4fd6-b515-bc818fa55368"
      },
      "source": [
        "%%time\n",
        "#VALIDATE THE ALGORITHM USING VALIDATE_DATA DATASET\n",
        "predictions = ba.predict(validate_data)\n",
        "print(\"Naive Bayes classifiers accuracy on validation data is: \", sum(predictions == validate_label)/validate_label.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes classifiers accuracy on validation data is:  0.7536666666666667\n",
            "CPU times: user 1.67 s, sys: 4.99 ms, total: 1.67 s\n",
            "Wall time: 1.67 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdv_B71yzrYs"
      },
      "source": [
        "TEST THE NAIVE BAYES CLASSIFIER ON 2000 TEST DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMa3oDdKz-HG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "a3f01b00-4972-42b1-fcd4-dace6b367fb4"
      },
      "source": [
        "%%time\n",
        "#TEST THE NAIVE BAYES CLASSIFIER ON FIRST 2000 VALUES OF TEST DATASET\n",
        "y_pred = ba.predict(data_try)\n",
        "print(\"The accuracy for naive bayes classifier on 2000 values of test data is\" , sum(y_pred == label_test)/label_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy for naive bayes classifier on 2000 values of test data is 0.729\n",
            "CPU times: user 745 ms, sys: 53.9 ms, total: 799 ms\n",
            "Wall time: 732 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbMbuFEZu14-"
      },
      "source": [
        "PREDICT THE LABELS OF TRANSFORMED TEST DATA USING THE NAIVE BAYES CLASSIFIER "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCqMS7W4ut6D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "6a3b960c-364d-4785-d6e8-a54e2ba276a7"
      },
      "source": [
        "%%time\n",
        "#PREDICT LABELS OF NEW DATA USING THE CLASSIFIER\n",
        "predictions_bayes = np.asarray(ba.predict(data_test_transform))\n",
        "print(\"The shape of the predicted data is\",predictions_bayes.shape)\n",
        "#print(\"The accuracy of naive bayes classifier on the test data is\" , sum(prediction_bayes == labels_of_full_dataset)/labels_of_full_dataset.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the predicted data is (5000,)\n",
            "CPU times: user 1.52 s, sys: 41.7 ms, total: 1.56 s\n",
            "Wall time: 1.51 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FDTWoS09Cka"
      },
      "source": [
        "LOGISTIC REGRESSION CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kb-NZoA9f4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "4edfe132-7b8e-46f4-cd4f-e996757dc35b"
      },
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "\n",
        "#CROSS ENTROPY CALCULATION\n",
        "def loss(p,p_hat):\n",
        "  return -np.vdot(p, np.log(p_hat))\n",
        "\n",
        "#LEARNING RATE CALCULATION\n",
        "def evaluation(X,y, b):\n",
        "  lr_rate = 0.0\n",
        "  n_samp = X.shape[0]\n",
        "  \n",
        "  for i in range(n_samp):\n",
        "    y_val = y[i]\n",
        "    x = X[i]   \n",
        "    prob = softmax(b @ x)\n",
        "    lr_rate += loss(y_val, prob)\n",
        "  return lr_rate\n",
        "\n",
        "#SOFTMAX VALUE CALCULATION\n",
        "def softmax(z):\n",
        "  return np.exp(z)/np.sum(np.exp(z))\n",
        "\n",
        "#GRADIENT DESCENT CALCULATION\n",
        "def GradientDescent(X,y,alpha):  \n",
        "  n_samp,n_feat = X.shape\n",
        "  label_col = y.shape[1]\n",
        "  num_epocs = 8\n",
        "  lr_rate_vals = []\n",
        "  #AUGMENT X\n",
        "  X = np.insert(X, 0, 1, axis = 1)               \n",
        "  b = np.zeros((label_col, n_feat+1))          \n",
        "  \n",
        "  for i in range(num_epocs):\n",
        "    perm = np.random.permutation(n_samp)\n",
        "    lr_rate = evaluation(X, y, b)\n",
        "    lr_rate_vals.append(lr_rate)\n",
        "    for r in perm:\n",
        "      x = X[r]\n",
        "      prob = softmax(b @ x)    \n",
        "      y_val = y[r]     \n",
        "      grad_Li = np.outer(prob - y_val, x)\n",
        "      b -= alpha * grad_Li\n",
        "  return b, lr_rate_vals\n",
        "\n",
        "#FUNCTION TO PREDICT LABELS OF DATA\n",
        "def predict(X, b):\n",
        "  prediction = []\n",
        "  X = np.insert(X, 0, 1, axis =1)\n",
        "  n_samp = X.shape[0] \n",
        "  for i in range(n_samp):\n",
        "    x = X[i] \n",
        "    prob = softmax(b @ x)      \n",
        "    max_prob = np.argmax(prob)\n",
        "    prediction.append(max_prob)\n",
        "  return prediction\n",
        "\n",
        "#TRAIN THE CLASSIFIER\n",
        "train_label1 = pd.get_dummies(train_label).values\n",
        "b,lr_rate_vals = GradientDescent(train_data,train_label1, alpha = 0.0001)\n",
        "\n",
        "#VALIDATE THE CLASSIFIER ON VALIDATE_DATA DATASET \n",
        "prediction = predict(validate_data, b)\n",
        "print(\"Logistic Regresion classifiers accuracy on validation data is: \", sum(prediction == validate_label)/validate_label.shape[0])\n",
        "\n",
        "#TEST THE LOGISTIC REGRESSION CLASSIFIER ON FIRST 2000 VALUES OF TEST DATASET\n",
        "y_pred = predict(data_try,b)\n",
        "print(\"The accuracy of logistic regression classifier on 2000 instances of test data is\" , sum(y_pred == label_test)/label_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regresion classifiers accuracy on validation data is:  0.8453333333333334\n",
            "The accuracy of logistic regression classifier on 2000 instances of test data is 0.829\n",
            "CPU times: user 8.41 s, sys: 7.86 ms, total: 8.42 s\n",
            "Wall time: 8.43 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf3TUmjcvv5F"
      },
      "source": [
        "PREDICT THE LABELS OF TRANSFORMED TEST DATA USING THE LOGISTIC REGRESSION CLASSIFIER\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VimdtWJJvwOx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "e4b0debf-9b9b-472e-b185-2451d69b0d0a"
      },
      "source": [
        "%%time\n",
        "#PREDICT THE LABELS OF TRANSFORMED TEST DATA \n",
        "predictions_logisticreg = np.asarray(predict(data_test_transform, b))\n",
        "print(\"The shape of the predicted data is\",predictions_logisticreg.shape)\n",
        "#print(\"The accuracy of logistic regression classifier on the test data is\" , sum(predictions_logisticreg == labels_of_full_dataset)/labels_of_full_dataset.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the predicted data is (5000,)\n",
            "CPU times: user 83.4 ms, sys: 968 µs, total: 84.4 ms\n",
            "Wall time: 83.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E29H-fso59lo"
      },
      "source": [
        "PRINT THE OUTPUT OF THE CLASIFIER WITH THE HIGHEST ACCURACY(KNN) TO AN OUTPUT FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5AfIzVc58_m"
      },
      "source": [
        "import numpy as np\n",
        "# assume output is the predicted labels\n",
        "with h5py.File('Output.h5','w') as H:\n",
        "  H.create_dataset('Output', data = predictions_knn)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}